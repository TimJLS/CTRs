{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))\n",
    "# sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import NullPool\n",
    "from sqlalchemy import sql\n",
    "from sqlalchemy import Table, MetaData\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def dump_scaler(obj, name, file_path=None):\n",
    "    if not str(name).endswith(\".scaler\"):\n",
    "        name = str(name) + \".scaler\"\n",
    "    if file_path is None:\n",
    "        file_path = os.path.abspath('')\n",
    "    full_path = file_path + '/'+ str(name)\n",
    "    joblib.dump(obj, full_path)\n",
    "\n",
    "def dump_encoder(obj, name, file_path=None):\n",
    "    if not str(name).endswith(\".encoder\"):\n",
    "        name = str(name) + \".encoder\"\n",
    "    if file_path is None:\n",
    "        file_path = os.path.abspath('')\n",
    "    full_path = file_path + '/'+ str(name)\n",
    "    joblib.dump(obj, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data: pd.DataFrame, label=None, params=None,\n",
    "                 categorical_feature=[], scaler_path=None, encoder_path=None):\n",
    "        self.handle = None\n",
    "        self._data = None\n",
    "        self._label = None\n",
    "        self.data = data.dropna()\n",
    "        self.label = label\n",
    "        self.categorical_feature = categorical_feature\n",
    "        self.params = params\n",
    "        if params is None:\n",
    "            raise ValueError(\"Specify params\")\n",
    "        self.scaler_path = scaler_path\n",
    "        self.encoder_path = encoder_path\n",
    "        self.is_construct = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<{0}> {1}\".format(\n",
    "            self.__class__.__name__,\n",
    "            json.dumps(\n",
    "                self.export_value(self.params),\n",
    "                sort_keys=True,\n",
    "                indent=4,\n",
    "                separators=(',', ': '),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def export_value(self, data):\n",
    "        if isinstance(data, dict):\n",
    "            data = dict((k, self.export_value(v))\n",
    "                        for k, v in data.items()\n",
    "                        if 'data' not in k)\n",
    "        elif isinstance(data, list):\n",
    "            data = [self.export_value(v) for v in data]\n",
    "        elif isinstance(data, pd.DataFrame):\n",
    "            data = data.to_dict()\n",
    "        elif isinstance(data, pd.Series):\n",
    "            data = data.to_dict()\n",
    "        elif isinstance(data, MinMaxScaler):\n",
    "            data = data.scale_.tolist()\n",
    "        elif isinstance(data, LabelEncoder):\n",
    "            data = data.classes_.tolist()\n",
    "        return data\n",
    "\n",
    "    def get_numerical_cols(self):\n",
    "        numerical_subset = []\n",
    "        if self.params is not None:\n",
    "            if 'numerical_cols' in self.params:\n",
    "                numerical_subset = self.params['numerical_cols']\n",
    "                assert type(numerical_subset)==list, \"numerical_cols should be list.\"\n",
    "            elif 'scale_cols' in self.params:\n",
    "                numerical_subset = self.params['scale_cols']\n",
    "                assert type(numerical_subset)==list, \"numerical_cols should be list.\"\n",
    "        return numerical_subset\n",
    "\n",
    "    def get_scale_cols(self):\n",
    "        scale_subset = []\n",
    "        if self.params is not None:\n",
    "            if 'scale_cols' in self.params:\n",
    "                scale_subset = self.params['scale_cols']\n",
    "                assert type(scale_subset)==list, \"scale_cols should be list.\"\n",
    "\n",
    "            elif 'numerical_cols' in self.params:\n",
    "                scale_subset = self.params['numerical_cols']\n",
    "                assert type(scale_subset)==list, \"scale_cols should be list.\"\n",
    "        return scale_subset\n",
    "\n",
    "    def get_label_encode_cols(self):\n",
    "        label_encode_subset = []\n",
    "        if self.params is not None:\n",
    "            if 'label_encode_cols' in self.params:\n",
    "                label_encode_subset = self.params['label_encode_cols']\n",
    "                assert type(label_encode_subset)==list, \"label_encode_cols should be list.\"\n",
    "        return label_encode_subset\n",
    "\n",
    "    def get_field(self, field_name):\n",
    "        if field_name == 'label':\n",
    "            if field_name in self.data.columns:\n",
    "                self.label = self.data.pop(field_name)\n",
    "            return self.label\n",
    "        elif field_name in self.data:\n",
    "            return self.data[field_name]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown field_name\")\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label is None:\n",
    "            self.label = self.get_field('label')\n",
    "        return self.label\n",
    "\n",
    "    def set_field(self, field_name, data):\n",
    "        if field_name == 'label':\n",
    "            self.label = data\n",
    "        else:\n",
    "            self.data[field_name] = data\n",
    "        return self\n",
    "\n",
    "    def set_label(self, label):\n",
    "        if label is not None:\n",
    "            self.set_field('label', label)\n",
    "            self.label = self.get_field('label')\n",
    "            self._label = self.label\n",
    "        return self\n",
    "\n",
    "    def transform_fields(self, trans_type=None):\n",
    "        if trans_type == 'numerical_cols':\n",
    "            numerical_cols = self.get_numerical_cols()\n",
    "            self._data[numerical_cols] = self.data[numerical_cols].apply(pd.to_numeric,\n",
    "                                                                         errors='ignore')\n",
    "\n",
    "        elif trans_type == 'scale_cols':\n",
    "            scale_cols = self.get_scale_cols()\n",
    "            if self.scaler_path is not None:\n",
    "                self.scaler = joblib.load(self.scaler_path)\n",
    "                self._data[scale_cols] = pd.DataFrame(\n",
    "                    self.scaler.inverse_transform(self.data[scale_cols]), columns=scale_cols)\n",
    "            else:\n",
    "                self.scaler = MinMaxScaler()\n",
    "                self._data[scale_cols] = pd.DataFrame(\n",
    "                    self.scaler.fit_transform(self.data[scale_cols]), columns=scale_cols)\n",
    "\n",
    "        elif trans_type == 'categorical_cols':\n",
    "            categorical_cols = self.categorical_feature\n",
    "            dummies = pd.get_dummies(self.data[categorical_cols])\n",
    "            self._data = pd.concat([self._data, dummies], axis=1)\n",
    "\n",
    "        elif trans_type == 'label_encode_cols':\n",
    "            label_encode_cols = self.get_label_encode_cols()\n",
    "            if self.encoder_path is not None:\n",
    "                self.label_encoder = joblib.load(self.encoder_path)\n",
    "                self._data[label_encode_cols] = pd.DataFrame(\n",
    "                    self.label_encoder.inverse_transform(self.data[label_encode_cols]))\n",
    "            else:\n",
    "                for col in label_encode_cols:\n",
    "                    self.label_encoder = LabelEncoder()\n",
    "                    self._data[col] = pd.DataFrame(\n",
    "                        self.label_encoder.fit_transform(self.data[col]))\n",
    "        return self\n",
    "\n",
    "    def full_transform(self):\n",
    "        if self._data is None:\n",
    "            self._data = pd.DataFrame()\n",
    "\n",
    "        if self.params is not None:\n",
    "            if 'numerical_cols' in self.params:\n",
    "                self.transform_fields(trans_type='numerical_cols')\n",
    "                \n",
    "            if 'scale_cols' in self.params:\n",
    "                self.transform_fields(trans_type='scale_cols')\n",
    "\n",
    "            if 'categorical_cols' in self.params:\n",
    "                self.transform_fields(trans_type='categorical_cols')\n",
    "\n",
    "            if 'label_encode_cols' in self.params:\n",
    "                self.transform_fields(trans_type='label_encode_cols')\n",
    "        return self\n",
    "\n",
    "    def _lazy_init(self, data, label=None, params=None,\n",
    "                   categorical_feature=None):\n",
    "        if data is None:\n",
    "            return self\n",
    "        params = {} if params is None else params\n",
    "        if isinstance(categorical_feature, list) and categorical_feature:\n",
    "            categorical_feature = pd.Index(categorical_feature)\n",
    "            if categorical_feature.isin(self.data.columns).all():\n",
    "                self.params['categorical_cols'] = list(categorical_feature)\n",
    "\n",
    "        if label is not None:\n",
    "            self.set_label(label)\n",
    "        self.get_label()\n",
    "        self.full_transform()\n",
    "\n",
    "    def construct(self):\n",
    "        if self._data is None:\n",
    "            self._lazy_init(self.data, label=self.label, params=self.params,\n",
    "                            categorical_feature=self.categorical_feature)\n",
    "        self.is_construct = True\n",
    "        return self\n",
    "\n",
    "    def train_eval_test_split(self, eval_size, test_size, random_state=27):\n",
    "        if not self.is_construct:\n",
    "            self.construct()\n",
    "        n = len(self.data)\n",
    "        e = round(n * eval_size)\n",
    "        t = round(n * test_size)\n",
    "        assert eval_size+test_size < 1, \"size bigger than 1\"\n",
    "        if n == 0:\n",
    "            raise ValueError\n",
    "        elif eval_size == 0 and test_size == 0:\n",
    "            raise ValueError\n",
    "\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        full_idxs = range(n)\n",
    "        eval_idx = np.random.choice(full_idxs, size=e, \n",
    "                                    replace=False)\n",
    "        full_idxs = list(set(full_idxs) - set(eval_idx))\n",
    "        test_idx = np.random.choice(full_idxs, size=t,\n",
    "                                    replace=False)\n",
    "        full_idxs = list(set(full_idxs) - set(test_idx))\n",
    "\n",
    "        tpl = ()\n",
    "\n",
    "        for idxs in [full_idxs, eval_idx, test_idx]:\n",
    "            dataset = Dataset(pd.DataFrame(), params=self.params,\n",
    "                              categorical_feature=self.categorical_feature)\n",
    "            for k, v in dataset.__dict__.items():\n",
    "                attr = self.__dict__[k]\n",
    "                if k in ['data', '_data', 'label', '_label']:\n",
    "                    dataset.__dict__[k] = attr[attr.index.isin(idxs)]\n",
    "            tpl += (dataset,)\n",
    "        return tpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook dataset.ipynb to script\n",
      "[NbConvertApp] Writing 9499 bytes to dataset.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --to script dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
